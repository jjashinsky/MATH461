---
title: "HW #11"
date: "`r format(Sys.time(), '%B %d, %Y')`"
author: "Jacob Jashinsky"
class: "Math 461"
hours: "7 Hours"
section: "01"
professor: "Lawrence Chilton"
due: "`r format(Sys.time(), '%B %d, %Y')`"
topic: "5.3.11a, 6.2.1, 6.2.3"
misc: "6.2.7, 6.3.3, 6.3.4, 6.3.5"
title-page: false
output: HomeworkBYUI::real_analysis_pdf
---
<!------------------------------------------------------------------------------>
<!------------------------------- Question 01 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{5.3.11a}

Use the Generalized Mean Value Theorem to furnish a proof of the $0/0$ case of L'Hospital's Rule (Theorem 5.3.6) 

A large portion of this work was adapted from https://www.math.hmc.edu/calculus/tutorials/lhopital/sketch_proof.html
\begin{solution}
The Generalized Mean Value theorem states that if $f$ and $g$ are continuous on a closed interval $[a,b]$ and differentiable on the open interval $(a,b)$, then there exists a point $c \in (a,b)$ where 
$$
[f(b) - f(a)]g'(c) = [g(b) - g(a)]f'(c)
$$

For this proof we will assume that that if $f$ and $g$ are continuous on a closed interval $[a,a+h]$ and differentiable on the open interval $(a,a+h)$, where $h >0$. \\

It will also be assumed that $f(a) = g(a) = 0$ and $g'(x) \ne 0$ for all $x \ne a$. Further, let $\lim_{x \to a^+} \frac{f'(x)}{g'(x)} = L$ \\

The generalized mean value theorem applies so it can be said that there exists a $c \in (a,b)$ such that 

$$
\frac{f(a+h) - f(a)}{g(a+h) -g(a)} = \frac{f'(c)}{g'(c)}.
$$
Since $f(a) = g(a) = 0$, it is also that 

$$
\frac{f(a+h) - f(a)}{g(a+h) -g(a)} = \frac{f(a+h)}{g(a+h)} = \frac{f'(c)}{g'(c)}.  
$$

If $h \to 0+$ from the right then the the interval would become smaller and the $c$ will get closer to the left end of the interval, $a$.

$$
\lim_{h \to 0^+} \frac{f'(c)}{g'(c)} = \lim_{x \to a^+} \frac{f'(x)}{g'(x)}
$$

Similarly it can be said that 

$$
\lim_{h \to 0^+} \frac{f(a)}{g(a)} = \lim_{x \to a^+} \frac{f(x)}{g(x)}
$$

Now since it is true that $\frac{f(a+h)}{g(a+h)} = \frac{f'(c)}{g'(c)}$, it follows that we can equate the two equations above as follows,

$$
\lim_{x \to a^+} \frac{f'(x)}{g'(x)} =  \lim_{x \to a^+} \frac{f(x)}{g(x)} = L.
$$
The same argument can be applied with left hand limits if the interval was $(a+h, a)$. Thus the limits together finish the proof. 
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 02 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.2.1}

Let 

$$
f_n(x) = \frac{nx}{1+nx^2}
$$

a) Find the point-wise limit of $(f_n)$ for all $n \in (0, \infty)$.

\begin{solution}
$$
f = \lim \frac{nx}{1+nx^2} = \lim \frac{x}{x^2} = \frac{1}{x}
$$
\end{solution}



b) Is the convergence uniform on $(0, \infty)$?

\begin{solution}
$$
\begin{aligned}
|f_n(x) - f(x)| &< \epsilon \\
\left| \frac{nx}{1+nx^2} - \frac{1}{x} \right| &< \epsilon \\
\left| \frac{-1}{x+nx^3} \right| &< \epsilon \\
|x+nx^3| &> 1/\epsilon \\
n &> \frac{1}{x^2} \left(\frac{1}{\epsilon x} - 1 \right)
\end{aligned}
$$

Given any $\epsilon$, when $x$ is really large, then a finite $N$ can be found. However, is $x$ is really close to $0$ then no $N$ can be found that would make the statement true. Therefore, $(f_n)$ does not converge uniformly on the interval $(0,\infty)$.     
\end{solution}


c) Is the convergence uniform on $(0, 1)$?

\begin{solution}
Once again note that given $N > \frac{1}{x^2} \left(\frac{1}{\epsilon x} - 1 \right)$, it would be impossible to find an $N$ when $x$ is close to $0$. $(f_n)$ is not uniformly convergent on the interval $(0,1)$. 
\end{solution}


d) Is the convergence uniform on $(1, \infty)$?

\begin{solution}
When $x$ is really large, $N > \frac{1}{x^2} \left(\frac{1}{\epsilon x} - 1 \right)$ then we see that any $N$ will do because the right side of the inequality will becoming negative. \\

So the smaller the $x$ will require a larger $N$. So this means that when $x=1$ we will require an $N$ such that $N > \left(\frac{1}{\epsilon} - 1 \right)$ for any given $\epsilon >0$. Thus it converges uniformly on the interval $(1, \infty)$.
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 03 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.2.3}

For each $n \in \mathbb{N}$ and $x \in [0,\infty)$. let 

$$
g_n(x) = \frac{x}{1+x^n} \ \ \ \text{and} \ \ \  
h_n(x)=\left\{
\begin{array}{ll}
      1 \ , &  \text{if} \ x \ge 1/n  \\
      nx \ , & \text{if} \ 0 \le x < 1/n
\end{array} 
\right.
$$

Answer the following questions for the sequences $(g_n)$ and $(h_n)$:

a) Find the point-wise limit on $[0,\infty)$.

\begin{solution}
$$
\lim g_n(x) = \left\{
\begin{array}{ll}
      x \ , & \text{if} \ 0 \le x < 1 \\
      1/2 \ , & \text{if} \ x = 1 \\
      0 \ , &  \text{if} \ x > 1
\end{array} 
\right.
$$
and also, 

$$
\lim h_n(x)=\left\{
\begin{array}{ll}
      0 \ , &  \text{if} \ x = 0  \\
      1 \ , & \text{if} \ x > 0
\end{array} 
\right.
$$
\end{solution}



b) Explain how we know that the convergence cannot be uniform on $[0,\infty)$.

\begin{solution}
The Contiuous Limit Theorem states that given a uniformly convergent sequence of functions, if $(f_n)$ is continuous at $c$, then $f$ is continuous at $c$. \\

We see that $(f_n)$ and $(h_n)$ are both continuous at a point $c$ but where $f$ and $g$ are not continuous at $c$. \\

The conclusion is false even though the hypotheis held true. This happened because the assumption of converging uniformly was not properly met.  
\end{solution}



c) Choose a smaller set over which the convergence is uniform and supply an argument to show that this is indeed the case. 


\begin{solution}
Define $(g_n)$ for the domain $x=1$. The limit is then equal to $1/2$. Now let $\epsilon > 0$ and $n > N$.

$$
|f_n(x) - f| = \left| \frac{x}{1+x^n} - \frac{1}{2} \right| = \left| \frac{1}{1+1^n} - \frac{1}{2} \right|  = 0 < \epsilon
$$

Define $(h_n)$ on the domain $x\ge1$. The limit is then equal to $1$. Now let $\epsilon > 0$ and $n > N \ge 1$.

$$
|h_n(x) - h| = \left| 1 - 1 \right|  = 0 < \epsilon
$$
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 04 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.2.7}

Let $f$ be uniformly continuous on all of $\mathbb{R}$, and define a sequence of functions by $f_n(x) = f(x+1/n)$. Show that $f_n \to f$ uniformly. Give an example to show that this proposition fails if $f$ is only assumed to be continuous and not uniformly continuous on $\mathbb{R}$. 


\begin{solution}
Let $f$ be uniform and $f_n(x) = f(x+1/n)$. Since $f$ is uniform there exists an $x,y \in \mathbb{R}$ such that $|y-x| < \delta$ implies that $|f(y) - f(x)| < \epsilon$

Let $|y-x| < \delta$ for every $\epsilon > 0$. Further let $y = x + 1/n$.   

$$
\begin{aligned}
|y - x| < \delta  &\Rightarrow |f(y) - f(x)| < \epsilon \\
|x + \frac{1}{n} - x| < \delta & \Rightarrow |f(1+\frac{1}{n}) - f(x)| < \epsilon \\
|x + \frac{1}{n} - x| < \delta & \Rightarrow |f_n(x) - f(x)| < \epsilon \\
\end{aligned}
$$
Thus $(f_n) \to f$ uniformly. 

The next step will be a proof by contradiction. Assume the function $f=1/x$ on the domain $x>0$ is uniformly continuous.   

$$
f_n(x) = f(1 + 1/n) = \frac{1}{x+1/n} = \frac{n}{nx+1}
$$
Since the function is uniform Cauchy Criterion for Uniform Convergence applies, which implies that for every $\epsilon > 0$ there exists an $N$ such that whenever $m,n > N$ implies $|f_n(x) - f_m(x)| < \epsilon$.

$$
\left| \frac{n}{nx+1} - \frac{m}{mx+1} \right| < \epsilon
$$

However this statement cannot be true for all $\epsilon$. No $N$ can be found when $x$ is arbitrarly close to 0. Therefore $f$ cannot be uniformly convergent.   
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 05 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.3.3}

Consider the sequence of functions

$$
f_n(x) = \frac{x}{1 + nx^2}.
$$

a) find the point on $\mathbb{R}$ where each $f_n(x)$ attains its maximum and minimum value. Use this to prove $(f_n)$ converges uniformly on $\mathbb{R}$. What is the limit function?

\begin{solution}
A function will attain its maximum and minimum values when $f_n' = 0$. 
$$
f_n' = \frac{(1+nx^2)(1) - (x)(2nx)}{(1+nx^2)^2} = \frac{1-nx^2}{(1+nx^2)^2} 
$$
Now to obtain the points where each $f_n$ reaches a maximum and minimum let $f_n' = 0$.

$$
\begin{aligned}
\frac{1-nx^2}{(1+nx^2)^2} &= 0 \\
1-nx^2 &= 0 \\
x^2 &= 1/n \\
x &= \pm \sqrt{1/n}
\end{aligned}
$$

The derivative obtains negative values when left of $-\sqrt{1/n}$ and to the right of $\sqrt{1/n}$. The derivative obtains positive values between $-\sqrt{1/n}$ and $\sqrt{1/n}$.Thus $(f_n)$ attains a minimum when $a = -\sqrt{1/n}$ and a maximum when $b = \sqrt{1/n}$. \\

Also, note that the value of the maximum or minimum is 
$$
\left| f_n \left( \frac{1}{\sqrt{n}} \right) \right| = \left| \frac{\frac{1}{\sqrt{n}}}{1+n\frac{1}{\sqrt{n}^2}} \right| = \left| \frac{1}{2\sqrt{n}} \right|. 
$$

As $n$ gets large, then $a$ and $b$ get closer to 0. However, as $a,b$ gets closer 0, then $f_n (a), f_n (b)$ also gets closer to 0. This means that the sequence of functions are converging to 0. \\

To prove that the function is uniformly converging to 0, let $\epsilon > 0$ and $n > N > \frac{1}{4\epsilon^2}$. 

$$
\begin{aligned}
n &> \frac{1}{4\epsilon^2} \\
\frac{1}{2\sqrt{n}} &< \epsilon \\
\left| \frac{x}{1 + nx^2} \right| < \left| \frac{1}{2\sqrt{n}} \right| &< |\epsilon| \\
\left| \frac{x}{1 + nx^2} - 0 \right| &< |\epsilon| \\
\end{aligned}
$$
Thus $(f_n) \to 0$ uniformly. 
\end{solution}

\newpage

b) Let $f = \lim f_n$. Compute $f'_n(x)$ and find all the values of $x$ for which $f'(x) = \lim f'_n(x)$.

\begin{solution}
Let $f = \lim f_n = 0$. 

$$
f'_n(x) = \frac{1-nx^2}{(1+nx^2)^2} = \frac{1-nx^2}{(1+2nx^2 + 2n^2x^4)}   
$$
$$
\lim f'_n(x) = \lim \frac{1-nx^2}{(1+2nx^2 + 2n^2x^4)} = \lim \frac{x^2}{(2x^2 + 4nx^4)} = 0
$$
The derivative of the sequene function will converge to 0 for an $x$ for which the function is defined. 
\end{solution}



\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 06 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.3.4}

Let
$$
h_n(x) = \frac{\sin(nx)}{\sqrt{n}}
$$
Show that $h_n \to 0$ uniformly on $\mathbb{R}$ but that the sequence of derivatives $(h'_n)$ diverges for every $x \in \mathbb{R}$.


\begin{solution}
To prove that $h_n$ converges uniformly it must be shown that whenever $n > N > \left(\frac{1}{\epsilon} \right)^2$ then $|h_n(x) - h(x) | < \epsilon$.

$$
\begin{aligned}
n &> \left(\frac{1}{\epsilon} \right)^2 \\
n &> \left(\frac{1}{\epsilon} \right)^2 \ge \left(\frac{\sin(nx)}{\epsilon} \right)^2 \\
\sqrt{n} &>  \frac{|\sin(nx)|}{\epsilon}  \\
\frac{\sqrt{n}}{|\sin(nx)|} &> \frac{1}{\epsilon} \\
\left| \frac{\sin(nx)}{\sqrt{n}} - 0 \right| &< \epsilon 
\end{aligned}
$$
Thus $(h_n) \to 0$ uniformly.

The derivative of $(h_n)$ is the equal to the following,
$$
h'_n(x) = \frac{n\cos(nx)}{\sqrt{n}}
$$
Now we will see that limit of $(h'_n)$ diverges for all $x \in \mathbb{R}$. 

$$
\lim_{n \to \infty} \frac{n\cos(nx)}{\sqrt{n}} = \lim_{n \to \infty} \sqrt{n}\cos(nx) = \infty
$$
This is true because $\cos(nx)$ is bounded by $[-1,1]$, but $\sqrt{n}$ will grow. If $nx$ is a multiple of $\pi/2, 3\pi/2$ then $\cos(nx) = 0$, however $nx$ is never always a multiple of $\pi/2, 3\pi/2$. The function will then oscillate in those cases, but this is also diverging.  \\

Therefore as $n \to \infty$, then $(h'_n) \to \infty$.    
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 07 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.3.5}

Let 

$$
g_n(x) = \frac{nx + x^2}{2n},
$$
and set $g(x) = \lim g_n(x)$. Show that $g$ is differentiable in two ways:

a) Compute $g(x)$ by algebraically taking the limit as $n \to \infty$ and then find $g'(x)$.

\begin{solution}
$$
\lim \frac{nx + x^2}{2n} = \lim \frac{x}{2} = \frac{x}{2}
$$
Since $g(x) = x/2$, then $g'(x) = 1/2$.
\end{solution}

b) Compute $g'(x)$ for each $n \in \mathbb{N}$ and show that the sequence of derivatives $(g'_n)$ converges uniformly on every interval $[-M,M]$. Use Theorem 6.3.3 to conclude $g'(x) = \lim g'(x)$.

\begin{solution}

$$
\frac{d}{dx} \left[ \frac{nx + x^2}{2n} \right] = \frac{1}{2n} \cdot \frac{d}{dx} \left[nx + x^2   \right] = \frac{n + 2x}{2n}
$$

Now I will show that $(f'_n) \to 1/2$ uniformly on the closed interval $[-M,M]$. Let $n > N > |M|/\epsilon$.

$$
\begin{aligned}
n &> \frac{|M|}{\epsilon} \\
\left| \frac{M}{n}\right| &< \epsilon \\
\left| \frac{x}{n} \right| \le \left| \frac{M}{n}\right| &< \epsilon \\
\left| \frac{n+ 2x - n}{2n} \right| &< \epsilon \\
\left| \frac{n+ 2x}{2n} - \frac{n}{2n} \right| &< \epsilon \\
\left| \frac{n+ 2x}{2n} - \frac{1}{2} \right| &< \epsilon \\
\end{aligned}
$$
Thus $(g'_n) \to 1/2$ uniformly on the closed interval $[0M,M]$. 

Now assume a point $x_0$ such that $x_0 \in [-M,M]$. Below we see that if we fix $x$ at the point $x_0$ the sequence of function is still uniformly convergent.

$$
\begin{aligned}
n &> \frac{|M|}{\epsilon} \\
\left| \frac{x_0}{n} \right| \le \left| \frac{M}{n}\right| &< \epsilon \\
\left| \frac{n+ 2x - n}{2n} \right| &< \epsilon \\
\left| \frac{n+ 2x_0}{2n} - \frac{1}{2} \right| &< \epsilon \\
\end{aligned}
$$
Theorem 6.3.3 can now apply because $(f_n)$ is differentiable, defined on the closed interval $[-M,M]$ and $(g'_n)$ was proven to be converging uniformly. Also, there exists a point $x_0 \in [-M,M]$ for which $g_n(x_0$ is convergent. \\

Thus by the theorem 6.3.3, $g$ is differentiable. Therefore $g' = 1/2$ and $\lim g'_n(x) = 1/2$, which implies $(g'_n) \to g'$.
\end{solution}

