---
title: "HW #12"
date: "`r format(Sys.time(), '%B %d, %Y')`"
author: "Jacob Jashinsky"
class: "Math 461"
hours: "6 Hours"
section: "01"
professor: "Lawrence Chilton"
due: "`r format(Sys.time(), '%B %d, %Y')`"
topic: "6.4.2a, 6.4.3, 6.4.5"
misc: "6.5.1, 6.5.3, 6.5.8"
title-page: false
output: HomeworkBYUI::real_analysis_pdf
---
<!------------------------------------------------------------------------------>
<!------------------------------- Question 01 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.4.2a} 

Decide whether the proposition is true or false, provide a short justification or counter example as appropriate.

If $\sum ^\infty _{n=1} g_n$ converges uniformly, then $(g_n)$ converges uniformly to zero. 

\begin{solution}
True. Since $\sum ^\infty _{n=1} g_n = g$, then it must be true that $\sum ^\infty _{m=1} g_{(m)} = g$. It follows that 
$$
\begin{aligned}
g-g &= 0 \\
\sum ^\infty _{n=1}g_{m} - \sum ^\infty _{n=1} g_n &= 0 \\
\lim_{n \to \infty} \left( g_{m} + g_{m-1} + g_{m-2} + .. + g_{n+1} + \sum ^n _{m=1}g_n - \sum ^n _{n=1} g_n \right) &= 0 \\
\lim_{n \to \infty} (g_{m} + g_{m-1} + g_{m-2} + .. + g_{n+1}) &= 0
\end{aligned}
$$
Clearly $(g_n)$ converges to 0, and the Cauchy Criterion for uniform convergence can be used to show that it converges uniformly. The expression above shows that there exists an $N$ such that $N \le n , m$ implies $|g_m - g_n| < \epsilon$. 
\end{solution}


<!------------------------------------------------------------------------------>
<!------------------------------- Question 02 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.4.3}

a) Show that 
$$
g(x) = \sum ^\infty _{n=0} \frac{\cos(2^nx)}{2^n}
$$
is continuous on all $\mathbb{R}$.

\begin{solution}
Consider the sequence $1/2^n$. Since $\cos(x)$ is bounded by 1 it can be said that $\left| \frac{\cos(2^nx)}{2^n} \right| \le \frac{1}{2^n}$ for all $x \in \mathbb{R}$. \\

Also note that series $\sum^\infty_{n=0} 1/2^n$ is geometric and converges. Weierstrass M-Test now applies, therefore, $\sum ^\infty _{n=0} \frac{\cos(2^nx)}{2^n}$ converges uniformly on $\mathbb{R}$. \\

Now theorem 6.4.2 states that since $g_n$ is continuous and the series converges uniformly, then $g(x)$ is continuous on its domain. 
\end{solution}


b) The function $g$ was cited in section 5.4 as an example of a continuous nowhere differentiable function. What happens if we try to use Theorem 6.4.3 to explore whether $g$ is differentiable? 

\begin{solution}
The assumptions are not met. The sum of the sequence $f'_n(x) = -\sin(2^nx)$ does not converge, therefore the theorem cannot apply. 
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 03 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.4.5}

a) Prove that 
$$
h(x) = \sum ^\infty _{n=1} \frac{x^n}{n^2} = x + \frac{x^2}{4} + \frac{x^3}{9} + ...
$$
is continuous on $[-1,1]$

\begin{solution}
Consider the sequence $1/n^2$. Since the domain of $h_n$ is bounded above by 1, it can be said that $\left| \frac{x^n}{n^2} \right| \le \frac{1}{2^n}$ for all $x \in [-1,1]$. \\

Also note that series $\sum^\infty_{n=0} 1/n^2$ is P-series and converges. Weierstrass M-Test now applies, therefore, $\sum ^\infty _{n=0} \frac{x^n}{n^2}$ converges uniformly on $[-1,1]$. \\

Now theorem 6.4.2 states that since $h_n$ is continuous and the series converges uniformly, then $h(x)$ is continuous on its domain. 
\end{solution}


b) The series 
$$
f(x) = \sum ^\infty _{n=1} \frac{x^n}{n} = x + \frac{x^2}{2} + \frac{x^3}{3} + ...
$$
converges for every $x$ in the half-open interval $[-1,1)$ but does not converge when $x=1$. For a fixed $x_0 \in (-1,1)$, explain how we can still use the Weierstrass M-test to prove that $f$ is continuous at $x_0$.


\begin{solution}
Since we know that the series converges for the half-open interval this can be our $M_n$. Chose an $x_0 \in (-1,1)$, choose a point $|c| \in [-1,1)$ such that $M_n = \frac{|c|^n}{n}$ and that $\left| \frac{x_0^n}{n} \right| \le \frac{|c|^n}{n}$. The sum of the sequence $M_n$ will converge, implying that $\sum  f_n(x_0)$ converges uniformly. \\

Theorem 6.4.2 can then be leveraged to show that since it converges uniformly it is also continuous at $x_0$. 
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 04 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.5.1}

Consider the function $g$ defined by the power series 
$$
g(x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + ...
$$
a) Is $g$ defined on $(-1,1)$? Is it continuous on this set? Is $g$ defined on $(-1,1]$? Is it continuous on this set? What happens on $[-1,1]$? Can the power series for $g(x)$ possibly converge for an other points $|x| > 1$? Explain.

\begin{solution}
To show that it is defined and continuous on the open interval $(-1,1)$, it must be shown where the power series converges. \\

The ratio test shows that,
$$
\begin{aligned}
\lim \left| \frac{\frac{x^{n+1}}{(n+1)}}{\frac{x^n}{n}} \right| &< 1 \\
\lim \left| \frac{nx}{n+1} \right| &< 1 \\
|x| &< 1
\end{aligned}
$$
The power series converges on the open interval $(-1,1)$. Theorem 6.5.7 now implies that $g$ is defined and continuous on the same interval. \\

It also converges uniformly o nthe half-open interval because $g_n(1)$ is a alternating series and converges by the alternating series test. Therefore, theorem 6.5.7 once again states that the power series is continuous on the the interval $(-1,1]$. \\

The same cannot be said about $[-1,1]$. $g_n(-1)$ is not longer alternating and is a harmonic series. Therefore it will not converge and will not be continuous at $x=-1$. \\

The greatest value for which the power series will converge is 1. It will not converge for any value greater because the ratio test has shown that any value greater than its boundary points will diverge.  
\end{solution}


b) For what values of $x$ is $g'(x)$ defined? Find a formula for $g'$.

\begin{solution}
Theorem 6.5.7 also states that $g$ is differentiable on the open interval $(-1,1)$, where $g'(x) = \sum_{n=1}^\infty (-1)^{n+1}x^{n-1}$. \\

However, $g'(1) = (1)^n$ and $g'(-1)=(-1)^{n+1}$ are not converging series, therefore, $g'$ is only defined on the open interval $(-1,1)$.
\end{solution}


\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 05 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.5.3}

Use the Weierstrass M-Test to prove Theorem 6.5.2

\begin{solution}
Theorem 6.5.2: If a power series $\sum^\infty _{n=0} a_nx^n$ converges absolutely at a point $x_0$, then it converges uniformly on the closed interval $[-c,c]$, where $c=|x_0|$. \\


Let $M_n = a_n|x_0|^n$ be a converging series. Choose a point $x_0$ and a point $|c| \le |x_0|$, and note that 
$$
\begin{aligned}
|c| &\le |x_0| \\
|c|^n &\le |x_0|^n \\
|a_nc^n| &\le |a_nx_0|^n \\
|f_n(c)| &\le |M_n|
\end{aligned}
$$

The M-Test now applies, therefore, $\sum^\infty _{n=0} a_nx^n$ converges at all points $|c| \le |x_0|$, or in other words, the power series converges on the interval $[-c,c]$.   
\end{solution}



\newpage
<!------------------------------------------------------------------------------>
<!------------------------------- Question 06 ---------------------------------->
<!------------------------------------------------------------------------------>
\exercise{6.5.8}

a) Show that the power series representations are unique. If we have 
$$
\sum ^\infty _{n=0} a_nx^n = \sum ^\infty _{n=0} b_nx^n
$$
for all $x$ in an interval $(-R, R)$, prove that $a_n = b_n$ for all $n=0,1,2,...$

\begin{solution}
For a direct proof assume $\sum ^\infty _{n=0} a_nx^n = \sum ^\infty _{n=0} b_nx^n$. 

It follows that,
$$
\begin{aligned}
\sum ^\infty _{n=0} a_nx^n - \sum ^\infty _{n=0} b_nx^n &= 0 \\
\sum ^\infty _{n=0} (a_nx^n - b_nx^n) &= 0 \\
\sum ^\infty _{n=0} ((a_n - b_n)x^n) &= 0 \\
\end{aligned}
$$
Note that the left is a power series, and it is being equated to $P_0$.  The only way the power series can exactly represent $P_0$ for all $x \in \mathbb{R}$ is if $(a_n - b_n)=0$. \\

This to the conclusion that $a_n = b_n$, and that power series representations are unique.  
\end{solution}


b) Let $f(x) = \sum^\infty _{n=0} a_nx^n$ converge on $(-R, R)$, and assume $f'(x) = f(x)$ for all $x \in (-R, R)$ and $f(0) = 1$. Deduce the values of $a_n$.


\begin{solution}
Let 
$$
f_n(x) = 1 + \frac{x}{1} + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \frac{x^5}{120} + \frac{x^6}{720} + ...
$$

note that the derivative is equal to the following,

$$
f'_n(x) = 1 + \frac{x}{1} + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \frac{x^5}{120} + ... \\
$$

It is also true that $f(0) = 1$. \\

We can conclude that $a_n = \frac{1}{n!}$
\end{solution}

